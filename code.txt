{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.1)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python/OpenAI/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza o upload de um arquivo para carregar informações ao modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=open(\"data_upload.txt\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria o assistente para acessar o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Analista de Dados\",\n",
    "    instructions=\"Você é um analista que analisa dados sobre vendas.\",\n",
    "    tools=[{\"type\":\"code_interpreter\"}],\n",
    "    tool_resources={\"code_interpreter\":{\"file_ids\":[file.id]}},\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função: Cria uma thread de conversa e envia a pergunta como mensagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pergunta = \"Qual o rating médio das vendas do supermercado\"\n",
    "#pergunta = \"Gere um grafico de vendas por linha de produtos\"\n",
    "pergunta = (\n",
    "    \"Gere 15 perguntas para conversação avançada em ingles que não estejam contidas no arquivo data_upload. \"\n",
    "    \"Nao repita as questões e nem mostre o numero de sequencia delas\"\n",
    ")\n",
    "\n",
    "\n",
    "# Criação da Thread\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executa a thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Nome de usuário premium\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aguarda a thread rodar\n",
    "while run.status in [\"queued\", \"in_progress\", \"cancelling\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "        \n",
    "    )\n",
    "    print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a resposta quando tivermos a resposta da thread\n",
    "if run.status == \"completed\":\n",
    "    mensagens = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(mensagens.data[0].content[0].text.value)\n",
    "else:\n",
    "    print(f\"Erro {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.1)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python/OpenAI/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "file.close()\n",
    "\n",
    "# Extrai o texto da resposta\n",
    "texto_resposta = mensagens.data[0].content[0].text.value\n",
    "\n",
    "# Extrai perguntas (linhas que começam com \"-\")\n",
    "perguntas = [linha.strip(\"- \").strip() for linha in texto_resposta.splitlines() if linha.strip().startswith(\"-\")]\n",
    "\n",
    "# Grava perguntas novas no final do arquivo\n",
    "if perguntas:\n",
    "    with open(\"data_upload.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        for pergunta in perguntas:\n",
    "            f.write(pergunta + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por hora esse print ficara commitado porque ja esta sendo considerado\n",
    "# mais abaixo\n",
    "# print(mensagens.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando a logica/passos do modelo para chegar na resposta\n",
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in run_steps.data[::-1]:\n",
    "    print(f\"\\n===Step {step.step_details.type}\")\n",
    "    if step.step_details.type == \"tool_calls\":\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(\"-\" * 10)\n",
    "            print(tool_call.code_interpreter.input)\n",
    "            print(\"-\" * 10)\n",
    "    if step.step_details.type == \"message_creation\":\n",
    "        message = client.beta.threads.messages.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        message_id=step.step_details.message_creation.message_id\n",
    "    )\n",
    "\n",
    "# print(message.content[0].text.value)\n",
    "# comentado acim apara quando a geração do output é grafico e não texto(conforme a pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#condicional adaptado para quando a pergunta solicita texto ou grafico\n",
    "#Função: Verifica se a resposta é texto ou imagem. Se for imagem, salva localmente.\n",
    "if message.content[0].type == \"text\":\n",
    "    print(message.content[0].text.value)\n",
    "if message.content[0].type == \"image_file\":\n",
    "    file_id = message.content[0].image_file.file_id\n",
    "    image_data = client.files.content(file_id)\n",
    "    with open(f\"files/{file.id}.png\", \"wb\") as f:\n",
    "        f.write(image_data.read())\n",
    "    print(f\"Imagem {file_id} salva\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
